{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85dcb1ef-14da-4906-b5e3-42550b57b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "import datasets\n",
    "import torchtext\n",
    "import tqdm\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2bf647-bb3e-47de-900a-a811042f4e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cab0a79-33e3-4697-b3df-c7311db35425",
   "metadata": {},
   "source": [
    "## ä»£ç è§£æ\n",
    "\n",
    "### 1. `os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'` çš„ä½œç”¨\n",
    "\n",
    "**æ”¹å˜äº†ä»€ä¹ˆ**ï¼š  \n",
    "è¿™è¡Œä»£ç å°†Hugging Faceçš„é»˜è®¤APIç«¯ç‚¹ä»å®˜æ–¹æº`https://huggingface.co`æ”¹ä¸ºå›½å†…é•œåƒæº`https://hf-mirror.com`ã€‚\n",
    "\n",
    "**ä¸ºä»€ä¹ˆä½¿ç”¨é•œåƒæº**ï¼š\n",
    "- ğŸš€ **åŠ é€Ÿä¸‹è½½**ï¼šå›½å†…æœåŠ¡å™¨ç½‘ç»œå»¶è¿Ÿæ›´ä½ï¼Œä¸‹è½½é€Ÿåº¦æ›´å¿«\n",
    "- ğŸ”’ **ç¨³å®šè¿æ¥**ï¼šé¿å…å›½é™…ç½‘ç»œæ³¢åŠ¨å¯¼è‡´çš„ä¸­æ–­\n",
    "- ğŸŒ **ç»•è¿‡é™åˆ¶**ï¼šæŸäº›ç½‘ç»œç¯å¢ƒæ— æ³•ç›´æ¥è®¿é—®åŸå§‹åŸŸå\n",
    "- âš–ï¸ **è´Ÿè½½å‡è¡¡**ï¼šå‡è½»å®˜æ–¹æœåŠ¡å™¨å‹åŠ›\n",
    "\n",
    "é€Ÿåº¦å¯¹æ¯”ï¼š\n",
    "- å®˜æ–¹æºï¼š200KB/s ~ 1MB/s\n",
    "- é•œåƒæºï¼šé€šå¸¸å¯è¾¾5MB/s ~ 20MB/s\n",
    "\n",
    "### 2. `dataset = datasets.load_dataset(\"bentrevett/multi30k\")` çš„åŠŸèƒ½\n",
    "\n",
    "**å®Œæˆçš„æ“ä½œ**ï¼š\n",
    "1. **æ£€æŸ¥ç¼“å­˜**ï¼šå…ˆæŸ¥æ‰¾`~/.cache/huggingface/datasets`ç›®å½•\n",
    "2. **ä¸‹è½½æ•°æ®**ï¼šè‹¥æœªç¼“å­˜åˆ™ä»é•œåƒç«™ä¸‹è½½\n",
    "3. **æ ¼å¼è½¬æ¢**ï¼šè‡ªåŠ¨è½¬æ¢ä¸ºé«˜æ•ˆçš„Arrowæ ¼å¼\n",
    "4. **è¿”å›å¯¹è±¡**ï¼šè¿”å›åŒ…å«ä¸‰ä¸ªå­é›†çš„`DatasetDict`å¯¹è±¡\n",
    "\n",
    "**æ•°æ®ç»“æ„**ï¼š\n",
    "```python\n",
    "{\n",
    "    'train': Dataset(29000æ¡),     # è®­ç»ƒé›†\n",
    "    'validation': Dataset(1014æ¡), # éªŒè¯é›†\n",
    "    'test': Dataset(1000æ¡)       # æµ‹è¯•é›†\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9ea34ca-b473-4b6a-886c-2e024b504cd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1. åŸºç¡€ä¿®æ”¹æ–¹å¼\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# 2. åŠ è½½æ•°æ®é›†ï¼ˆè‡ªåŠ¨èµ°é•œåƒï¼‰\n",
    "dataset = load_dataset(\"multi30k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c37ce63a-640b-4a9f-9e42-eec9396094f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 29000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1014\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90b4901-04ff-428d-9573-1cacf36dda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"validation\"],\n",
    "    dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66309f2-c584-44ea-8275-5222981c5de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiÃŸe MÃ¤nner sind im Freien in der NÃ¤he vieler BÃ¼sche.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "771e40b0-89b0-4c3a-8e91-cf4be0cabc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "de_nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88795385-92c7-4746-a134-39093e091e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"What a lovely day it is today!\"\n",
    "\n",
    "[token.text for token in en_nlp.tokenizer(string)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca107f-4be0-4d17-a42c-f3140c6fef52",
   "metadata": {},
   "source": [
    "\n",
    "## `tokenize_example` å‡½æ•°è¯¦è§£\n",
    "\n",
    "### åŠŸèƒ½æè¿°\n",
    "è¿™æ˜¯ä¸€ä¸ªç”¨äºå¤„ç†åŒè¯­å¹³è¡Œè¯­æ–™ï¼ˆè‹±è¯­-å¾·è¯­ï¼‰çš„åˆ†è¯é¢„å¤„ç†å‡½æ•°ï¼Œä¸»è¦å®Œæˆä»¥ä¸‹è½¬æ¢ï¼š\n",
    "```\n",
    "åŸå§‹å¥å­ â†’ åˆ†è¯ â†’ å¤§å°å†™å¤„ç† â†’ æ·»åŠ ç‰¹æ®Šæ ‡è®°\n",
    "```\n",
    "\n",
    "### å‚æ•°è¯´æ˜\n",
    "| å‚æ•° | ç±»å‹ | ä½œç”¨ |\n",
    "|------|------|------|\n",
    "| `example` | dict | åŒ…å«\"en\"(è‹±æ–‡)å’Œ\"de\"(å¾·æ–‡)é”®çš„å­—å…¸ |\n",
    "| `en_nlp` | spaCyæ¨¡å‹ | è‹±è¯­åˆ†è¯å™¨ |\n",
    "| `de_nlp` | spaCyæ¨¡å‹ | å¾·è¯­åˆ†è¯å™¨ |\n",
    "| `max_length` | int | æœ€å¤§åˆ†è¯é•¿åº¦ï¼ˆæˆªæ–­è¶…é•¿å¥å­ï¼‰ |\n",
    "| `lower` | bool | æ˜¯å¦è½¬ä¸ºå°å†™ |\n",
    "| `sos_token` | str | å¥å­èµ·å§‹æ ‡è®° |\n",
    "| `eos_token` | str | å¥å­ç»“æŸæ ‡è®° |\n",
    "\n",
    "### è®¾è®¡ç›®çš„\n",
    "1. ç»Ÿä¸€ä¸åŒè¯­è¨€çš„é¢„å¤„ç†æµç¨‹\n",
    "2. ä¸ºSeq2Seqæ¨¡å‹å‡†å¤‡æ ‡å‡†åŒ–çš„è¾“å…¥æ ¼å¼\n",
    "3. æ§åˆ¶è¾“å…¥åºåˆ—çš„æœ€å¤§é•¿åº¦ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc29531-96b8-41ce-a259-4d1063d1a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example, en_nlp, de_nlp, max_length, lower, sos_token, eos_token):\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
    "    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        de_tokens = [token.lower() for token in de_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae78689f-d759-420a-88dc-ac3505da3a27",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## ç‰¹æ®Šæ ‡è®°ä¸mapå‡½æ•°è§£æ\n",
    "\n",
    "### <sos>å’Œ<eos>æ ‡è®°è¯¦è§£\n",
    "\n",
    "| æ ‡è®°    | å…¨ç§°                  | ä½œç”¨                                                                 |\n",
    "|---------|-----------------------|----------------------------------------------------------------------|\n",
    "| `<sos>` | Start Of Sentence     | æ ‡è¯†å¥å­å¼€å§‹ä½ç½®ï¼Œä¸ºæ¨¡å‹æä¾›åºåˆ—èµ·å§‹ä¿¡å·                             |\n",
    "| `<eos>` | End Of Sentence       | æ ‡è¯†å¥å­ç»“æŸä½ç½®ï¼Œç”¨äºæ§åˆ¶ç”Ÿæˆæ–‡æœ¬é•¿åº¦å’Œæ ‡è®°åºåˆ—ç»ˆæ­¢                 |\n",
    "\n",
    "**å…³é”®ç‰¹æ€§**ï¼š\n",
    "1. åœ¨åºåˆ—åˆ°åºåˆ—(Seq2Seq)æ¨¡å‹ä¸­ï¼š\n",
    "   - ç¼–ç å™¨ï¼šé€šå¸¸åªéœ€æ·»åŠ `<eos>`\n",
    "   - è§£ç å™¨ï¼šéœ€è¦åŒæ—¶æ·»åŠ `<sos>`å’Œ`<eos>`\n",
    "2. å®é™…å®ç°æ—¶ä¼šè¢«è½¬æ¢ä¸ºç‰¹æ®ŠIDï¼ˆå¦‚`<sos>=1`, `<eos>=2`ï¼‰\n",
    "\n",
    "### mapå‡½æ•°å·¥ä½œæœºåˆ¶\n",
    "\n",
    "```python\n",
    "dataset.map(\n",
    "    tokenize_example,    # åº”ç”¨çš„å¤„ç†å‡½æ•°\n",
    "    fn_kwargs=fn_kwargs  # ä¼ é€’ç»™å‡½æ•°çš„å‚æ•°å­—å…¸\n",
    ")\n",
    "```\n",
    "\n",
    "**æ ¸å¿ƒåŠŸèƒ½**ï¼š\n",
    "1. **æ‰¹é‡å¤„ç†**ï¼šè‡ªåŠ¨éå†æ•°æ®é›†æ‰€æœ‰æ ·æœ¬åº”ç”¨å¤„ç†å‡½æ•°\n",
    "2. **å‚æ•°ä¼ é€’**ï¼šé€šè¿‡`fn_kwargs`å°†é…ç½®å‚æ•°ä¼ é€’ç»™æ¯ä¸ªå¤„ç†å‡½æ•°\n",
    "3. **æƒ°æ€§æ‰§è¡Œ**ï¼šHuggingFaceæ•°æ®é›†ç‰¹æœ‰çš„å»¶è¿Ÿè®¡ç®—æœºåˆ¶\n",
    "\n",
    "**å¤„ç†æµç¨‹**ï¼š\n",
    "1. å¯¹æ¯ä¸ªæ ·æœ¬è°ƒç”¨`tokenize_example(example, **fn_kwargs)`\n",
    "2. è‡ªåŠ¨ç»´æŠ¤å¤„ç†åçš„æ•°æ®é›†ç»“æ„\n",
    "3. åªæœ‰åœ¨å®é™…è®¿é—®æ•°æ®æ—¶æ‰æ‰§è¡Œè®¡ç®—ï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰\n",
    "\n",
    "**ç­‰æ•ˆå®ç°**ï¼š\n",
    "```python\n",
    "processed_data = []\n",
    "for example in train_data:\n",
    "    processed_data.append(tokenize_example(example, **fn_kwargs))\n",
    "```\n",
    "\n",
    "**ä¼˜åŠ¿**ï¼š\n",
    "- ä»£ç ç®€æ´æ€§ï¼š1è¡Œä»£ç æ›¿ä»£æ˜¾å¼å¾ªç¯\n",
    "- æ€§èƒ½ä¼˜åŒ–ï¼šè‡ªåŠ¨å¹¶è¡Œå¤„ç†ï¼ˆå¯é€šè¿‡`num_proc`å‚æ•°æ§åˆ¶ï¼‰\n",
    "- æ•°æ®ä¸€è‡´æ€§ï¼šç¡®ä¿æ‰€æœ‰æ•°æ®åº”ç”¨ç›¸åŒçš„é¢„å¤„ç†é€»è¾‘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dcb6859-a463-4446-8874-d885f0e601c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0a9fff5c3d48618103947c86e8e73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1014 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cf33389ebe4c77a11b6191ba0b7ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 1_000\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp,\n",
    "    \"de_nlp\": de_nlp,\n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1b0e889-bebd-4935-9f4d-ebdc067fcdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiÃŸe MÃ¤nner sind im Freien in der NÃ¤he vieler BÃ¼sche.',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'zwei',\n",
       "  'junge',\n",
       "  'weiÃŸe',\n",
       "  'mÃ¤nner',\n",
       "  'sind',\n",
       "  'im',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nÃ¤he',\n",
       "  'vieler',\n",
       "  'bÃ¼sche',\n",
       "  '.',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e064a72-7c2a-4285-b08b-827d10786eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "de_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"de_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "955f5790-e262-4922-a9d9-658ca5cbd52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<sos>', '<eos>', 'a', '.', 'in', 'the', 'on', 'man']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcc6bece-57ce-4e3a-9ea3-a89be064df47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<sos>', '<eos>', '.', 'ein', 'einem', 'in', 'eine', ',']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6feb956e-1ddf-4dd7-8755-6098573d3289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90caca53-d128-464f-8c0e-568e4b86e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert en_vocab[unk_token] == de_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == de_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d99b16b-ee19-4e05-892e-e41af3ac7535",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(unk_index)\n",
    "de_vocab.set_default_index(unk_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d70cf5aa-0b45-4e42-a7ec-8a6adaea1d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[956, 2169, 173, 0, 821]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\n",
    "en_vocab.lookup_indices(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e593a-4862-4ad9-a94e-02d1f5ac4662",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## è¯æ±‡è¡¨è½¬æ¢ä¸­\"crime\"å˜æˆ<unk>çš„åŸå› è§£æ\n",
    "\n",
    "### æ ¸å¿ƒåŸå› \n",
    "\"crime\"è¢«è½¬æ¢æˆ`<unk>`æ˜¯å› ä¸ºè¯¥å•è¯æ²¡æœ‰è¢«åŒ…å«åœ¨`en_vocab`è¯æ±‡è¡¨ä¸­ï¼Œè€Œ`set_default_index(unk_index)`è®¾ç½®äº†é»˜è®¤å¤„ç†æ–¹å¼ã€‚\n",
    "\n",
    "### è¯¦ç»†è§£é‡Š\n",
    "\n",
    "1. **è¯æ±‡è¡¨å·¥ä½œåŸç†**ï¼š\n",
    "   - `en_vocab`æ˜¯ä¸€ä¸ªé¢„å®šä¹‰çš„è¯æ±‡è¡¨å¯¹è±¡\n",
    "   - å®ƒåŒ…å«è®­ç»ƒé›†ä¸­å‡ºç°è¿‡çš„å•è¯åŠå…¶å¯¹åº”ç´¢å¼•\n",
    "   - é€šè¿‡`set_default_index(unk_index)`è®¾ç½®äº†æœªçŸ¥è¯çš„å¤„ç†æ–¹å¼\n",
    "\n",
    "2. **è½¬æ¢è¿‡ç¨‹åˆ†æ**ï¼š\n",
    "   ```python\n",
    "   # åŸå§‹tokenåˆ—è¡¨\n",
    "   tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\n",
    "   \n",
    "   # è½¬æ¢ä¸ºç´¢å¼•æ—¶\n",
    "   en_vocab.lookup_indices(tokens) â†’ [956, 2169, 173, 0, 821]\n",
    "   # \"crime\"ä¸åœ¨è¯æ±‡è¡¨ä¸­ï¼Œè¿”å›é¢„è®¾çš„unk_index(0)\n",
    "   \n",
    "   # ç´¢å¼•è½¬å›tokenæ—¶\n",
    "   en_vocab.lookup_tokens([...,0,...]) â†’ [...,'<unk>',...]\n",
    "   # ç´¢å¼•0å¯¹åº”<unk>æ ‡è®°\n",
    "   ```\n",
    "\n",
    "3. **ä¸ºä»€ä¹ˆä¼šå‡ºç°è¿™ç§æƒ…å†µ**ï¼š\n",
    "   - è®­ç»ƒæ•°æ®é‡ä¸è¶³ï¼Œæœªè¦†ç›–æ‰€æœ‰å¯èƒ½å•è¯\n",
    "   - \"crime\"å¯èƒ½æ˜¯ä½é¢‘è¯ï¼Œè¢«è¯æ±‡è¡¨è¿‡æ»¤æ‰äº†\n",
    "   - å¯èƒ½æ˜¯é¢„å¤„ç†é˜¶æ®µè¢«é”™è¯¯åœ°ç§»é™¤äº†\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d842dd69-42b1-4fef-94cf-78f44a168192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'watching', '<unk>', 'shows']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.lookup_tokens(en_vocab.lookup_indices(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb4772-9360-494b-9d2a-82a3ea484ec5",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## ä»£ç åŠŸèƒ½è§£æ\n",
    "\n",
    "### numericalize_example å‡½æ•°\n",
    "\n",
    "**æ ¸å¿ƒä½œç”¨**ï¼š\n",
    "- å®ç°æ–‡æœ¬tokenåˆ°æ•°å€¼IDçš„è½¬æ¢\n",
    "- ä¸ºç¥ç»ç½‘ç»œæ¨¡å‹å‡†å¤‡æ•°å€¼åŒ–è¾“å…¥\n",
    "\n",
    "**å¤„ç†é€»è¾‘**ï¼š\n",
    "1. æ¥æ”¶åŒ…å«åŒè¯­tokenåºåˆ—çš„å­—å…¸è¾“å…¥\n",
    "2. åˆ†åˆ«æŸ¥è¯¢è‹±è¯­å’Œå¾·è¯­çš„è¯æ±‡è¡¨\n",
    "3. å°†tokenåºåˆ—è½¬æ¢ä¸ºå¯¹åº”çš„IDåºåˆ—\n",
    "4. è¿”å›åŒ…å«è½¬æ¢ç»“æœçš„å­—å…¸\n",
    "\n",
    "### mapå‡½æ•°åº”ç”¨\n",
    "\n",
    "æ ¸å¿ƒä½œç”¨ï¼š\n",
    "â€¢ æ‰¹é‡æ‰§è¡Œæ•°å€¼åŒ–è½¬æ¢\n",
    "\n",
    "â€¢ ä¿æŒæ•°æ®é›†å¤„ç†çš„ä¸€è‡´æ€§\n",
    "\n",
    "\n",
    "å®ç°æœºåˆ¶ï¼š\n",
    "1. é€šè¿‡fn_kwargsä¼ é€’è¯æ±‡è¡¨å‚æ•°\n",
    "2. è‡ªåŠ¨éå†æ•°æ®é›†æ‰€æœ‰æ ·æœ¬\n",
    "3. å¯¹æ¯ä¸ªæ ·æœ¬åº”ç”¨numericalize_exampleå‡½æ•°\n",
    "4. è¿”å›è½¬æ¢åçš„æ–°æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f00c9d7d-0782-4ca7-ac75-f227d6d91b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, en_vocab, de_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    de_ids = de_vocab.lookup_indices(example[\"de_tokens\"])\n",
    "    return {\"en_ids\": en_ids, \"de_ids\": de_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "337c193f-4ac4-4d75-983d-d2bec6bbf088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb2ae4084714875b8b196ee73587db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1014 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516d133ac6c9457bb8f4c8b228fc30cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fn_kwargs = {\"en_vocab\": en_vocab, \"de_vocab\": de_vocab}\n",
    "\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "843f3fa7-3d71-4534-acc9-d321caaeda82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiÃŸe MÃ¤nner sind im Freien in der NÃ¤he vieler BÃ¼sche.',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'zwei',\n",
       "  'junge',\n",
       "  'weiÃŸe',\n",
       "  'mÃ¤nner',\n",
       "  'sind',\n",
       "  'im',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nÃ¤he',\n",
       "  'vieler',\n",
       "  'bÃ¼sche',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'en_ids': [2, 16, 24, 15, 25, 778, 17, 57, 80, 202, 1312, 5, 3],\n",
       " 'de_ids': [2, 18, 26, 253, 30, 84, 20, 88, 7, 15, 110, 7647, 3171, 4, 3]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e8a448c-1fef-43ca-b178-7767733fe7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"de_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "valid_data = valid_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_data = test_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e9b35d4-55c3-4d45-b86c-e3cf56849c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([   2,   16,   24,   15,   25,  778,   17,   57,   80,  202, 1312,    5,\n",
       "            3]),\n",
       " 'de_ids': tensor([   2,   18,   26,  253,   30,   84,   20,   88,    7,   15,  110, 7647,\n",
       "         3171,    4,    3]),\n",
       " 'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiÃŸe MÃ¤nner sind im Freien in der NÃ¤he vieler BÃ¼sche.',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'zwei',\n",
       "  'junge',\n",
       "  'weiÃŸe',\n",
       "  'mÃ¤nner',\n",
       "  'sind',\n",
       "  'im',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nÃ¤he',\n",
       "  'vieler',\n",
       "  'bÃ¼sche',\n",
       "  '.',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9145f-2a3b-4f29-b112-d0ef1669414d",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## æ•°æ®å¤„ç†å‡½æ•°è§£æ\n",
    "\n",
    "### `get_collate_fn` å‡½æ•°\n",
    "\n",
    "**ä½œç”¨**ï¼š\n",
    "åˆ›å»ºç”¨äºå¤„ç†æ‰¹æ¬¡æ•°æ®çš„æ•´ç†å‡½æ•°(collate function)ï¼Œä¸»è¦å®ç°ï¼š\n",
    "1. ä»æ‰¹æ¬¡ä¸­æå–è‹±è¯­å’Œå¾·è¯­çš„IDåºåˆ—\n",
    "2. å¯¹ä¸ç­‰é•¿åºåˆ—è¿›è¡Œå¡«å……å¯¹é½\n",
    "3. è¿”å›æ•´ç†åçš„æ‰¹æ¬¡æ•°æ®\n",
    "\n",
    "**å…³é”®å‚æ•°**ï¼š\n",
    "- `pad_index`: ç”¨äºå¡«å……çš„ç´¢å¼•å€¼\n",
    "\n",
    "**å®ç°ç»†èŠ‚**ï¼š\n",
    "1. å†…éƒ¨å®šä¹‰`collate_fn`å‡½æ•°å¤„ç†å®é™…æ‰¹æ¬¡æ•°æ®\n",
    "2. ä½¿ç”¨`nn.utils.rnn.pad_sequence`è¿›è¡Œåºåˆ—å¡«å……\n",
    "3. è¿”å›åŒ…å«å¡«å……ååºåˆ—çš„å­—å…¸\n",
    "\n",
    "### `get_data_loader` å‡½æ•°\n",
    "\n",
    "**ä½œç”¨**ï¼š\n",
    "åˆ›å»ºPyTorchæ•°æ®åŠ è½½å™¨(DataLoader)ï¼Œä¸»è¦åŠŸèƒ½ï¼š\n",
    "1. é…ç½®æ•°æ®åŠ è½½å‚æ•°\n",
    "2. åº”ç”¨è‡ªå®šä¹‰çš„æ•´ç†å‡½æ•°\n",
    "3. æ§åˆ¶æ•°æ®åŠ è½½è¡Œä¸º\n",
    "\n",
    "**å…³é”®å‚æ•°**ï¼š\n",
    "- `dataset`: è¦åŠ è½½çš„æ•°æ®é›†\n",
    "- `batch_size`: æ‰¹æ¬¡å¤§å°\n",
    "- `pad_index`: ä¼ é€’ç»™æ•´ç†å‡½æ•°çš„å¡«å……ç´¢å¼•\n",
    "- `shuffle`: æ˜¯å¦æ‰“ä¹±æ•°æ®é¡ºåº\n",
    "\n",
    "**å®ç°ç»†èŠ‚**ï¼š\n",
    "1. è°ƒç”¨`get_collate_fn`è·å–æ•´ç†å‡½æ•°\n",
    "2. åˆ›å»ºPyTorch DataLoaderå®ä¾‹\n",
    "3. é…ç½®æ‰¹æ¬¡åŠ è½½å’Œé¡ºåºæ§åˆ¶\n",
    "\n",
    "**ç»„åˆä½¿ç”¨æ•ˆæœ**ï¼š\n",
    "è¿™ä¸¤ä¸ªå‡½æ•°é…åˆå®ç°äº†ï¼š\n",
    "- è‡ªåŠ¨æ‰¹æ¬¡å¤„ç†\n",
    "- åºåˆ—é•¿åº¦å¯¹é½\n",
    "- é«˜æ•ˆæ•°æ®åŠ è½½\n",
    "ä¸ºæ¨¡å‹è®­ç»ƒæä¾›æ ¼å¼ç»Ÿä¸€çš„æ‰¹æ¬¡æ•°æ®\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f00ebf9-0f21-4975-a1c4-4f520018072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_de_ids = [example[\"de_ids\"] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"de_ids\": batch_de_ids,\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08f24c82-7053-4d30-bf3e-3bac80cc9ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_collate_fn.<locals>.collate_fn(batch)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader\n",
    "get_collate_fn(pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65c18f7d-7614-42ec-b06e-a320a099ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85664703-9d73-4242-ad8c-ba73124e5491",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## Encoderç±»è§£æ\n",
    "\n",
    "### è¾“å…¥å‚æ•°\n",
    "| å‚æ•°å | ç±»å‹ | æè¿° |\n",
    "|--------|------|------|\n",
    "| `input_dim` | int | è¾“å…¥è¯æ±‡è¡¨å¤§å° |\n",
    "| `embedding_dim` | int | è¯åµŒå…¥ç»´åº¦ |\n",
    "| `hidden_dim` | int | LSTMéšè—å±‚ç»´åº¦ |\n",
    "| `n_layers` | int | LSTMå †å å±‚æ•° |\n",
    "| `dropout` | float | Dropoutæ¦‚ç‡ |\n",
    "\n",
    "### æ ¸å¿ƒç»„ä»¶\n",
    "1. **è¯åµŒå…¥å±‚** (`nn.Embedding`)\n",
    "   - å°†è¾“å…¥çš„å•è¯ç´¢å¼•æ˜ å°„ä¸ºå¯†é›†å‘é‡è¡¨ç¤º\n",
    "   - ç»´åº¦è½¬æ¢ï¼š`[seq_len, batch_size]` â†’ `[seq_len, batch_size, embedding_dim]`\n",
    "\n",
    "2. **LSTMå±‚** (`nn.LSTM`)\n",
    "   - å¤„ç†å˜é•¿åºåˆ—è¾“å…¥\n",
    "   - æ”¯æŒå¤šå±‚å †å å’Œdropout\n",
    "   - è‡ªåŠ¨ç»´æŠ¤éšè—çŠ¶æ€å’Œç»†èƒçŠ¶æ€\n",
    "\n",
    "3. **Dropoutå±‚** (`nn.Dropout`)\n",
    "   - åœ¨è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒéƒ¨åˆ†ç¥ç»å…ƒ\n",
    "   - é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›\n",
    "\n",
    "### forwardå¤„ç†æµç¨‹\n",
    "1. **è¾“å…¥åµŒå…¥**\n",
    "   ```python\n",
    "   embedded = self.dropout(self.embedding(src))\n",
    "   ```\n",
    "   - è¾“å…¥å½¢çŠ¶ï¼š`[src_len, batch_size]`\n",
    "   - è¾“å‡ºå½¢çŠ¶ï¼š`[src_len, batch_size, embedding_dim]`\n",
    "\n",
    "2. **LSTMå¤„ç†**\n",
    "   ```python\n",
    "   outputs, (hidden, cell) = self.rnn(embedded)\n",
    "   ```\n",
    "   - è‡ªåŠ¨å¤„ç†å˜é•¿åºåˆ—\n",
    "   - è¿”å›ï¼š\n",
    "     - `outputs`: æ¯ä¸ªæ—¶é—´æ­¥çš„é¡¶å±‚éšè—çŠ¶æ€\n",
    "     - `hidden`: æœ€åæ—¶é—´æ­¥çš„æ‰€æœ‰å±‚éšè—çŠ¶æ€\n",
    "     - `cell`: æœ€åæ—¶é—´æ­¥çš„æ‰€æœ‰å±‚ç»†èƒçŠ¶æ€\n",
    "\n",
    "### è¾“å‡ºè¯´æ˜\n",
    "| è¾“å‡º | å½¢çŠ¶ | æè¿° |\n",
    "|------|------|------|\n",
    "| `outputs` | `[src_len, batch_size, hidden_dim]` | æ¯ä¸ªæ—¶é—´æ­¥çš„ç¼–ç è¡¨ç¤º |\n",
    "| `hidden` | `[n_layers, batch_size, hidden_dim]` | æœ€ç»ˆéšè—çŠ¶æ€ï¼ˆç”¨äºDecoderåˆå§‹åŒ–ï¼‰ |\n",
    "| `cell` | `[n_layers, batch_size, hidden_dim]` | æœ€ç»ˆç»†èƒçŠ¶æ€ï¼ˆç”¨äºDecoderåˆå§‹åŒ–ï¼‰ |\n",
    "\n",
    "### è®¾è®¡ç‰¹ç‚¹\n",
    "1. æ”¯æŒæ‰¹å¤„ç†å¹¶è¡Œè®¡ç®—\n",
    "2. è‡ªåŠ¨å¤„ç†å˜é•¿åºåˆ—\n",
    "3. é€šè¿‡dropoutå®ç°æ­£åˆ™åŒ–\n",
    "4. è¾“å‡ºåŒ…å«å®Œæ•´çš„åºåˆ—ä¿¡æ¯å’Œæœ€ç»ˆçŠ¶æ€\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "519707be-70a5-4060-af37-8a8767cbd15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5aaff-bfb4-4249-9d68-4e0bb2bd6cee",
   "metadata": {},
   "source": [
    "## Decoderç±»è§£æ\n",
    "\n",
    "### æ ¸å¿ƒåŠŸèƒ½\n",
    "Decoderå®ç°åºåˆ—ç”Ÿæˆä»»åŠ¡ï¼Œå°†ç¼–ç åçš„è¡¨ç¤ºé€æ­¥è§£ç ä¸ºç›®æ ‡è¯­è¨€åºåˆ—ã€‚é‡‡ç”¨å…¸å‹çš„LSTMæ¶æ„ï¼Œé€šè¿‡è‡ªå›å½’æ–¹å¼é€ä¸ªç”Ÿæˆè¾“å‡ºtokenã€‚\n",
    "\n",
    "### è¾“å…¥å‚æ•°\n",
    "| å‚æ•° | ç±»å‹ | æè¿° |\n",
    "|------|------|------|\n",
    "| `input` | LongTensor | å½“å‰æ—¶é—´æ­¥çš„è¾“å…¥tokenç´¢å¼•ï¼Œå½¢çŠ¶ä¸º`[batch_size]` |\n",
    "| `hidden` | FloatTensor | ç¼–ç å™¨ä¼ é€’çš„éšè—çŠ¶æ€ï¼Œå½¢çŠ¶`[n_layers, batch_size, hidden_dim]` |\n",
    "| `cell` | FloatTensor | ç¼–ç å™¨ä¼ é€’çš„ç»†èƒçŠ¶æ€ï¼Œå½¢çŠ¶`[n_layers, batch_size, hidden_dim]` |\n",
    "\n",
    "### ç»„ä»¶ç»“æ„\n",
    "1. **è¯åµŒå…¥å±‚** (`nn.Embedding`)\n",
    "   - å°†ç¦»æ•£tokenç´¢å¼•æ˜ å°„ä¸ºè¿ç»­å‘é‡ç©ºé—´\n",
    "   - è¾“å…¥ç»´åº¦ï¼š`output_dim` (ç›®æ ‡è¯æ±‡è¡¨å¤§å°)\n",
    "   - è¾“å‡ºç»´åº¦ï¼š`embedding_dim`\n",
    "\n",
    "2. **LSTMå±‚** (`nn.LSTM`)\n",
    "   - å¤šå±‚LSTMç»“æ„ï¼Œä¿æŒä¸Encoderç›¸åŒçš„éšè—ç»´åº¦\n",
    "   - ä½¿ç”¨dropoutè¿›è¡Œæ­£åˆ™åŒ–\n",
    "   - å¤„ç†åºåˆ—ç”Ÿæˆä»»åŠ¡\n",
    "\n",
    "3. **å…¨è¿æ¥å±‚** (`nn.Linear`)\n",
    "   - å°†LSTMè¾“å‡ºæŠ•å½±åˆ°ç›®æ ‡è¯æ±‡è¡¨ç©ºé—´\n",
    "   - è®¡ç®—æ¯ä¸ªtokençš„ç”Ÿæˆæ¦‚ç‡\n",
    "\n",
    "### å¤„ç†æµç¨‹\n",
    "1. **è¾“å…¥é¢„å¤„ç†**\n",
    "   ```python\n",
    "   input = input.unsqueeze(0)  # [batch_size] â†’ [1, batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "967d5340-b9b4-401a-ba92-dae55d4ed43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # context = [n layers, batch size, hidden dim]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # output = [seq length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # seq length and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, hidden dim]\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # cell = [n layers, batch size, hidden dim]\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dba93f-fa5f-4faa-a322-2fb338542938",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## Seq2Seqç±»è§£æ\n",
    "\n",
    "### æ•´ä½“æ¶æ„\n",
    "Seq2Seqæ¨¡å‹ç”±Encoderå’ŒDecoderç»„æˆï¼Œå®ç°ç«¯åˆ°ç«¯çš„åºåˆ—è½¬æ¢ä»»åŠ¡ï¼ˆå¦‚æœºå™¨ç¿»è¯‘ï¼‰ã€‚é€šè¿‡Encoderç¼–ç æºåºåˆ—ï¼ŒDecoderé€æ­¥ç”Ÿæˆç›®æ ‡åºåˆ—ã€‚\n",
    "\n",
    "### forwardå¤„ç†æµç¨‹\n",
    "\n",
    "1. **åˆå§‹åŒ–é˜¶æ®µ**\n",
    "   ```python\n",
    "   outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "   hidden, cell = self.encoder(src)\n",
    "   input = trg[0, :]  # åˆå§‹è¾“å…¥ä¸º<sos>æ ‡è®°\n",
    "   ```\n",
    "   - åˆ›å»ºè¾“å‡ºå¼ é‡å­˜å‚¨æ¯ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹\n",
    "   - é€šè¿‡Encoderè·å–æºåºåˆ—çš„ç¼–ç çŠ¶æ€\n",
    "   - ä½¿ç”¨ç›®æ ‡åºåˆ—çš„é¦–ä¸ªtoken(<sos>)åˆå§‹åŒ–Decoder\n",
    "\n",
    "2. **åºåˆ—ç”Ÿæˆå¾ªç¯**\n",
    "   ```python\n",
    "   for t in range(1, trg_length):\n",
    "       output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "       outputs[t] = output\n",
    "       top1 = output.argmax(1)  # è·å–é¢„æµ‹token\n",
    "       input = trg[t] if teacher_force else top1  # é€‰æ‹©è¾“å…¥æ¥æº\n",
    "   ```\n",
    "   - æ¯ä¸ªæ—¶é—´æ­¥ï¼š\n",
    "     1. é€šè¿‡Decoderç”Ÿæˆå½“å‰è¾“å‡ºå’Œæ›´æ–°çŠ¶æ€\n",
    "     2. å­˜å‚¨é¢„æµ‹åˆ†å¸ƒåˆ°outputs\n",
    "     3. æ ¹æ®teacher forcingç­–ç•¥å†³å®šä¸‹ä¸€æ­¥è¾“å…¥\n",
    "\n",
    "3. **è¾“å‡ºç»“æœ**\n",
    "   - è¿”å›å½¢çŠ¶ä¸º`[trg_length, batch_size, trg_vocab_size]`çš„é¢„æµ‹å¼ é‡\n",
    "   - æ¯ä¸ªä½ç½®åŒ…å«å¯¹åº”æ—¶é—´æ­¥çš„è¯æ±‡è¡¨æ¦‚ç‡åˆ†å¸ƒ\n",
    "\n",
    "### Teacher Forcingæœºåˆ¶\n",
    "\n",
    "| æœºåˆ¶ | è¯´æ˜ | æ•°å­¦è¡¨ç¤º |\n",
    "|------|------|----------|\n",
    "| **å¯ç”¨æ—¶** (æ¦‚ç‡=teacher_forcing_ratio) | ä½¿ç”¨çœŸå®ç›®æ ‡åºåˆ—ä½œä¸ºDecoderè¾“å…¥ | $input_t = trg_t$ |\n",
    "| **ç¦ç”¨æ—¶** | ä½¿ç”¨Decoderä¸Šä¸€æ­¥çš„é¢„æµ‹ç»“æœä½œä¸ºè¾“å…¥ | $input_t = \\argmax(output_{t-1})$ |\n",
    "\n",
    "**å·¥ä½œç‰¹ç‚¹**ï¼š\n",
    "1. è®­ç»ƒæ—¶éšæœºåˆ‡æ¢ä¸¤ç§æ¨¡å¼ï¼ˆé€šè¿‡`random.random()`å®ç°ï¼‰\n",
    "2. å…¸å‹è®¾ç½®ï¼šåˆå§‹teacher_forcing_ratio=0.75ï¼Œéšç€è®­ç»ƒé€æ­¥é™ä½\n",
    "3. éªŒè¯/æµ‹è¯•æ—¶é€šå¸¸è®¾ä¸º0ï¼ˆå®Œå…¨ä½¿ç”¨æ¨¡å‹è‡ªèº«é¢„æµ‹ï¼‰\n",
    "\n",
    "### è®¾è®¡è¦ç‚¹\n",
    "1. **ç»´åº¦ä¸€è‡´æ€§æ£€æŸ¥**ï¼šæ„é€ å‡½æ•°éªŒè¯Encoder/Decoderçš„hidden_dimå’Œn_layersåŒ¹é…\n",
    "2. **è®¾å¤‡ç®¡ç†**ï¼šæ˜¾å¼å¤„ç†å¼ é‡è®¾å¤‡ï¼ˆé€šè¿‡self.deviceï¼‰\n",
    "3. **åºåˆ—ç”Ÿæˆ**ï¼šé€šè¿‡å¾ªç¯å®ç°è‡ªå›å½’ç”Ÿæˆï¼Œæ”¯æŒå˜é•¿è¾“å‡º\n",
    "4. **çµæ´»æ§åˆ¶**ï¼šteacher_forcing_ratioå¯åŠ¨æ€è°ƒæ•´è®­ç»ƒè¡Œä¸º\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4736301d-0c39-4d7d-902d-6ba31271b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert (\n",
    "            encoder.n_layers == decoder.n_layers\n",
    "        ), \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "        # input = [batch size]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden and previous cell states\n",
    "            # receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [n layers, batch size, hidden dim]\n",
    "            # cell = [n layers, batch size, hidden dim]\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "832d8ca7-bb86-4b37-a522-280331d3c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(de_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ç¼–ç å™¨åˆå§‹åŒ–\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    encoder_dropout,\n",
    ")\n",
    "# è§£ç å™¨åˆå§‹åŒ–\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    decoder_dropout,\n",
    ")\n",
    "# Seq2Seqæ¨¡å‹æ•´åˆ\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ef193e6-4ceb-460f-91b4-77f8c52e2542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7853, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf0025c5-f117-450c-81da-c4d986d75ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 13,898,501 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdad372c-f2ab-4eae-8482-4d6393ab79a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "573ead36-c266-4269-8699-6b3f14aa5d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "527b98e2-f2cc-47b7-aa8b-afcc88e698a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼\n",
    "    model.train()\n",
    "    # åˆå§‹åŒ–å½“å‰epochçš„æ€»æŸå¤±\n",
    "    epoch_loss = 0\n",
    "    # éå†æ•°æ®åŠ è½½å™¨ä¸­çš„æ¯ä¸ªæ‰¹æ¬¡\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        # è·å–æºè¯­è¨€åºåˆ—å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡\n",
    "        src = batch[\"de_ids\"].to(device)\n",
    "        # è·å–ç›®æ ‡è¯­è¨€åºåˆ—å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡\n",
    "        trg = batch[\"en_ids\"].to(device)\n",
    "        # srcçš„å½¢çŠ¶ä¸º [src length, batch size]\n",
    "        # trgçš„å½¢çŠ¶ä¸º [trg length, batch size]\n",
    "        \n",
    "        # æ¸…ç©ºä¼˜åŒ–å™¨çš„æ¢¯åº¦\n",
    "        optimizer.zero_grad()\n",
    "        # å°†æºåºåˆ—å’Œç›®æ ‡åºåˆ—è¾“å…¥æ¨¡å‹ï¼Œè·å–è¾“å‡º\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        # outputçš„å½¢çŠ¶ä¸º [trg length, batch size, trg vocab size]\n",
    "        \n",
    "        # è·å–ç›®æ ‡è¯æ±‡è¡¨çš„å¤§å°\n",
    "        output_dim = output.shape[-1]\n",
    "        # å»æ‰è¾“å‡ºçš„ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥ï¼ˆ<sos>ï¼‰ï¼Œå¹¶è°ƒæ•´å½¢çŠ¶ä»¥é€‚é…æŸå¤±å‡½æ•°\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # outputçš„å½¢çŠ¶ä¸º [(trg length - 1) * batch size, trg vocab size]\n",
    "        \n",
    "        # å»æ‰ç›®æ ‡åºåˆ—çš„ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥ï¼ˆ<sos>ï¼‰ï¼Œå¹¶è°ƒæ•´å½¢çŠ¶ä»¥é€‚é…æŸå¤±å‡½æ•°\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trgçš„å½¢çŠ¶ä¸º [(trg length - 1) * batch size]\n",
    "        \n",
    "        # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„æŸå¤±\n",
    "        loss = criterion(output, trg)\n",
    "        # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦\n",
    "        loss.backward()\n",
    "        # å¯¹æ¢¯åº¦è¿›è¡Œè£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        # æ›´æ–°æ¨¡å‹å‚æ•°\n",
    "        optimizer.step()\n",
    "        # ç´¯åŠ å½“å‰æ‰¹æ¬¡çš„æŸå¤±\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # è¿”å›å½“å‰epochçš„å¹³å‡æŸå¤±\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6640f38c-f962-4b3d-8e1c-7a5d246d9318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"de_ids\"].to(device)\n",
    "            trg = batch[\"en_ids\"].to(device)\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, trg, 0)  # turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f0a0ab4-1b88-4958-ae59-ed440fd9a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.026 | Train PPL: 152.277\n",
      "\tValid Loss:   4.861 | Valid PPL: 129.150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1 # å› æ¨¡å‹è®­ç»ƒå¯¹è®¡ç®—èµ„æºè¦æ±‚è¾ƒé«˜ï¼Œæ­¤å¤„åªè®¾ç«‹äº†ä¸€è½®è®­ç»ƒã€‚\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"tut1-model.pt\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e10ababa-e800-43df-8850-b45685feccd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"tut1-model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dad37c3b-46f7-4f8a-8b1e-cc7138e84386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab,\n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(sentence, str):\n",
    "            tokens = [token.text for token in de_nlp.tokenizer(sentence)]\n",
    "        else:\n",
    "            tokens = [token for token in sentence]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        tokens = [sos_token] + tokens + [eos_token]\n",
    "        ids = de_vocab.lookup_indices(tokens)\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        hidden, cell = model.encoder(tensor)\n",
    "        inputs = en_vocab.lookup_indices([sos_token])\n",
    "        for _ in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == en_vocab[eos_token]:\n",
    "                break\n",
    "        tokens = en_vocab.lookup_tokens(inputs)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3755d0c-11d2-48a9-bbcf-61182650a5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.',\n",
       " 'A man in an orange hat starring at something.')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = test_data[0][\"de\"]\n",
    "expected_translation = test_data[0][\"en\"]\n",
    "\n",
    "sentence, expected_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ca3f535-e8a1-4a83-a531-8d818f0fe312",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab,\n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49fd16c0-f72b-40e8-ae0a-a4389abe2fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'a',\n",
       " 'man',\n",
       " 'in',\n",
       " 'a',\n",
       " 'a',\n",
       " 'shirt',\n",
       " 'is',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " '.',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c13bb2c-1f53-4de6-a2ec-573ffa169a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
